<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>
  File: README
  
    &mdash; Documentation by YARD 0.9.37
  
</title>

  <link rel="stylesheet" href="css/style.css" type="text/css" />

  <link rel="stylesheet" href="css/common.css" type="text/css" />

<script type="text/javascript">
  pathId = "README";
  relpath = '';
</script>


  <script type="text/javascript" charset="utf-8" src="js/jquery.js"></script>

  <script type="text/javascript" charset="utf-8" src="js/app.js"></script>


  </head>
  <body>
    <div class="nav_wrap">
      <iframe id="nav" src="class_list.html?1"></iframe>
      <div id="resizer"></div>
    </div>

    <div id="main" tabindex="-1">
      <div id="header">
        <div id="menu">
  
    <a href="_index.html">Index</a> &raquo; 
    <span class="title">File: README</span>
  
</div>

        <div id="search">
  
    <a class="full_list_link" id="class_list_link"
        href="class_list.html">

        <svg width="24" height="24">
          <rect x="0" y="4" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="12" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="20" width="24" height="4" rx="1" ry="1"></rect>
        </svg>
    </a>
  
</div>
        <div class="clear"></div>
      </div>

      <div id="content"><div id='filecontents'><h1 id="red-candle-native-llms-for-ruby"><code>red-candle</code> Native LLMs for Ruby üöÄ</h1>

<p><a href="https://github.com/assaydepot/red-candle/actions/workflows/build.yml"><img src="https://github.com/assaydepot/red-candle/actions/workflows/build.yml/badge.svg" alt="build"></a>
<a href="https://badge.fury.io/rb/red-candle"><img src="https://badge.fury.io/rb/red-candle.svg" alt="Gem Version"></a></p>

<p>Run state-of-the-art <strong>language models directly from Ruby</strong>. No Python, no APIs, no external services - just Ruby with blazing-fast Rust under the hood. Hardware accelerated with <strong>Metal (Mac)</strong> and <strong>CUDA (NVIDIA).</strong></p>

<h2 id="install-chat-in-30-seconds">Install &amp; Chat in 30 Seconds</h2>

<p><a href="https://www.youtube.com/watch?v=hbyFCyh8esk"><img src="https://img.youtube.com/vi/hbyFCyh8esk/0.jpg" alt="red-candle quickstart"></a></p>

<pre class="code bash"><code class="bash"># Install the gem
gem install red-candle
</code></pre>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&#39;</span></span>

<span class='comment'># Download a model (one-time, ~650MB) - Mistral, Llama3, Gemma all work!
</span><span class='id identifier rubyid_llm'>llm</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/LLM.html#from_pretrained-class_method" title="Candle::LLM.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> 
                                  <span class='label'>gguf_file:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Chat with it - no API calls, running locally in your Ruby process!
</span><span class='id identifier rubyid_messages'>messages</span> <span class='op'>=</span> <span class='lbracket'>[</span>
  <span class='lbrace'>{</span> <span class='label'>role:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>user</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>content:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Explain Ruby in one sentence</span><span class='tstring_end'>&quot;</span></span> <span class='rbrace'>}</span>
<span class='rbracket'>]</span>

<span class='id identifier rubyid_puts'>puts</span> <span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_chat'>chat</span><span class='lparen'>(</span><span class='id identifier rubyid_messages'>messages</span><span class='rparen'>)</span>
<span class='comment'># =&gt; &quot;Ruby is a dynamic, object-oriented programming language known for its 
</span><span class='comment'>#     simplicity, elegance, and productivity, often used for web development 
</span><span class='comment'>#     with frameworks like Rails.&quot;
</span></code></pre>

<h2 id="what-just-happened">What Just Happened?</h2>

<p>You just ran a 1.1-billion parameter AI model inside Ruby. The model lives in your process memory, runs on your hardware (CPU/GPU), and responds instantly without network latency.</p>

<h2 id="stream-responses-like-a-pro">Stream Responses Like a Pro</h2>

<pre class="code ruby"><code class="ruby"><span class='comment'># Watch the AI think in real-time
</span><span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_chat_stream'>chat_stream</span><span class='lparen'>(</span><span class='id identifier rubyid_messages'>messages</span><span class='rparen'>)</span> <span class='kw'>do</span> <span class='op'>|</span><span class='id identifier rubyid_token'>token</span><span class='op'>|</span>
  <span class='id identifier rubyid_print'>print</span> <span class='id identifier rubyid_token'>token</span>
<span class='kw'>end</span>
</code></pre>

<h2 id="why-this-matters">Why This Matters</h2>

<ul>
<li><strong>Privacy</strong>: Your data never leaves your machine</li>
<li><strong>Speed</strong>: No network overhead, direct memory access</li>
<li><strong>Control</strong>: Fine-tune generation parameters, access raw tokens</li>
<li><strong>Integration</strong>: It&#39;s just Ruby objects - use it anywhere Ruby runs</li>
</ul>

<h2 id="supports">Supports</h2>

<ul>
<li><strong>Tokenizers</strong>: Access the tokenizer directly</li>
<li><strong>EmbeddingModel</strong>: Generate embeddings for text</li>
<li><strong>Reranker</strong>: Rerank documents based on relevance</li>
<li><strong>NER</strong>: Named Entity Recognition directly from Ruby</li>
<li><strong>LLM</strong>: Chat with Large Language Models (e.g., Llama, Mistral, Gemma)</li>
</ul>

<hr>

<h2 id="usage">Usage</h2>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&quot;</span></span>

<span class='id identifier rubyid_x'>x</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/Tensor.html" title="Candle::Tensor (class)">Tensor</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/Tensor.html#new-class_method" title="Candle::Tensor.new (method)">new</a></span></span><span class='lparen'>(</span><span class='lbracket'>[</span><span class='int'>1</span><span class='comma'>,</span> <span class='int'>2</span><span class='comma'>,</span> <span class='int'>3</span><span class='comma'>,</span> <span class='int'>4</span><span class='comma'>,</span> <span class='int'>5</span><span class='comma'>,</span> <span class='int'>6</span><span class='rbracket'>]</span><span class='comma'>,</span> <span class='symbol'>:i64</span><span class='rparen'>)</span>
<span class='id identifier rubyid_x'>x</span> <span class='op'>=</span> <span class='id identifier rubyid_x'>x</span><span class='period'>.</span><span class='id identifier rubyid_reshape'>reshape</span><span class='lparen'>(</span><span class='lbracket'>[</span><span class='int'>3</span><span class='comma'>,</span> <span class='int'>2</span><span class='rbracket'>]</span><span class='rparen'>)</span>
<span class='comment'># [[1., 2.],
</span><span class='comment'>#  [3., 4.],
</span><span class='comment'>#  [5., 6.]]
</span><span class='comment'># Tensor[[3, 2], f32]
</span></code></pre>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&#39;</span></span>

<span class='comment'># Default model (JinaBERT) on CPU
</span><span class='id identifier rubyid_model'>model</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/EmbeddingModel.html" title="Candle::EmbeddingModel (class)">EmbeddingModel</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/EmbeddingModel.html#new-class_method" title="Candle::EmbeddingModel.new (method)">new</a></span></span>
<span class='id identifier rubyid_embedding'>embedding</span> <span class='op'>=</span> <span class='id identifier rubyid_model'>model</span><span class='period'>.</span><span class='id identifier rubyid_embedding'>embedding</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hi there!</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Specify device (CPU, Metal, or CUDA)
</span><span class='id identifier rubyid_device'>device</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_cpu'>cpu</span>     <span class='comment'># or Candle::Device.metal, Candle::Device.cuda
</span><span class='id identifier rubyid_model'>model</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/EmbeddingModel.html" title="Candle::EmbeddingModel (class)">EmbeddingModel</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/EmbeddingModel.html#new-class_method" title="Candle::EmbeddingModel.new (method)">new</a></span></span><span class='lparen'>(</span>
  <span class='label'>model_path:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>jinaai/jina-embeddings-v2-base-en</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span>
  <span class='label'>device:</span> <span class='id identifier rubyid_device'>device</span>
<span class='rparen'>)</span>
<span class='id identifier rubyid_embedding'>embedding</span> <span class='op'>=</span> <span class='id identifier rubyid_model'>model</span><span class='period'>.</span><span class='id identifier rubyid_embedding'>embedding</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hi there!</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Reranker also supports device selection
</span><span class='id identifier rubyid_reranker'>reranker</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/Reranker.html" title="Candle::Reranker (class)">Reranker</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/Reranker.html#new-class_method" title="Candle::Reranker.new (method)">new</a></span></span><span class='lparen'>(</span>
  <span class='label'>model_path:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>cross-encoder/ms-marco-MiniLM-L-12-v2</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span>
  <span class='label'>device:</span> <span class='id identifier rubyid_device'>device</span>
<span class='rparen'>)</span>
<span class='id identifier rubyid_results'>results</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_rerank'>rerank</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>query</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>doc1</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>doc2</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>doc3</span><span class='tstring_end'>&quot;</span></span><span class='rbracket'>]</span><span class='rparen'>)</span>
</code></pre>

<h2 id="llm-support">LLM Support</h2>

<p>Red-Candle now supports Large Language Models (LLMs) with GPU acceleration!</p>

<h3 id="supported-models">Supported Models</h3>

<ul>
<li><strong>Gemma</strong>: Google&#39;s Gemma models (e.g., <code>google/gemma-2b</code>, <code>google/gemma-7b</code>, <code>google/gemma-2b-it</code>)</li>
<li><strong>Llama</strong>: Llama 2 and Llama 3 models (e.g., <code>TinyLlama/TinyLlama-1.1B-Chat-v1.0</code>, <code>meta-llama/Llama-2-7b-hf</code>, <code>NousResearch/Llama-2-7b-hf</code>)</li>
<li><strong>Mistral</strong>: All Mistral models (e.g., <code>mistralai/Mistral-7B-Instruct-v0.1</code>)</li>
</ul>

<h3 id="quantized-model-support-gguf">Quantized Model Support (GGUF)</h3>

<p>Red-Candle supports quantized models in GGUF format, offering 4-8x memory reduction:</p>

<blockquote>
<p><strong>Note on GGUF Support</strong>: Red-Candle now uses a unified GGUF loader that automatically detects the model architecture from the GGUF file. This means all GGUF models (including Mistral models from TheBloke) should now work correctly! The loader automatically selects the appropriate tokenizer based on the model type to ensure proper text generation.</p>
</blockquote>

<pre class="code ruby"><code class="ruby"><span class='comment'># Load quantized models - always specify the GGUF filename
</span><span class='id identifier rubyid_llm'>llm</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/LLM.html#from_pretrained-class_method" title="Candle::LLM.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>TheBloke/Llama-2-7B-Chat-GGUF</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> 
                                  <span class='label'>device:</span> <span class='id identifier rubyid_device'>device</span><span class='comma'>,</span> 
                                  <span class='label'>gguf_file:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>llama-2-7b-chat.Q4_K_M.gguf</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Register custom tokenizer mappings for your models
</span><span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_register_tokenizer'><span class='object_link'><a href="Candle/LLM.html#register_tokenizer-class_method" title="Candle::LLM.register_tokenizer (method)">register_tokenizer</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>my-org/my-model-GGUF</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>my-org/my-tokenizer</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Popular quantized model sources:
</span><span class='comment'># - TheBloke: Extensive collection of GGUF models
</span><span class='comment'># - Search HuggingFace for &quot;GGUF&quot; models
</span></code></pre>

<p><strong>Memory usage comparison (7B models):</strong></p>

<ul>
<li>Full precision: ~28 GB</li>
<li>Q8_0 (8-bit): ~7 GB - Best quality, larger size</li>
<li>Q5_K_M (5-bit): ~4.5 GB - Very good quality<br></li>
<li>Q4_K_M (4-bit): ~4 GB - Recommended default, best balance</li>
<li>Q3_K_M (3-bit): ~3 GB - Good for memory-constrained systems</li>
</ul>

<p><strong>Quantization levels explained:</strong></p>

<ul>
<li><strong>Q8_0</strong>: Almost identical to full model, use when quality is paramount</li>
<li><strong>Q5_K_M</strong>: Excellent quality with good compression</li>
<li><strong>Q4_K_M</strong>: Best balance of quality/size/speed (recommended default)</li>
<li><strong>Q3_K_M</strong>: Noticeable quality reduction but very compact</li>
<li><strong>Q2_K</strong>: ‚ö†Ô∏è <strong>Not recommended</strong> - Can cause inference errors due to extreme quantization</li>
</ul>

<blockquote>
<p><strong>Warning</strong>: Q2_K quantization can lead to &quot;weight is negative, too large or not a valid number&quot; errors during inference. Use Q3_K_M or higher for stable operation.</p>

<h3 id="huggingface-login-warning">‚ö†Ô∏è Huggingface login warning</h3>

<p>Many models, including the one below, require you to agree to the terms. You&#39;ll need to:</p>

<ol>
<li>Login to <a href="https://huggingface.co">Huggingface</a></li>
<li>Agree to the terms. For example: <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1">here</a></li>
<li>Authenticate your session. Simplest way is with <code>huggingface-cli login</code>. Detail here: <a href="https://huggingface.co/docs/huggingface_hub/en/guides/cli">Huggingface CLI</a></li>
</ol>

<p>More details here: <a href="HUGGINGFACE.md">Huggingface Authentication</a></p>
</blockquote>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&#39;</span></span>

<span class='comment'># Choose your device
</span><span class='id identifier rubyid_device'>device</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_cpu'>cpu</span>     <span class='comment'># CPU (default)
</span><span class='id identifier rubyid_device'>device</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_metal'>metal</span>   <span class='comment'># Apple GPU (Metal)
</span><span class='id identifier rubyid_device'>device</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_cuda'>cuda</span>    <span class='comment'># NVIDIA GPU (CUDA)
</span>
<span class='comment'># Load a model
</span><span class='id identifier rubyid_llm'>llm</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/LLM.html#from_pretrained-class_method" title="Candle::LLM.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>google/gemma-2b-it</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>device:</span> <span class='id identifier rubyid_device'>device</span><span class='rparen'>)</span>  <span class='comment'># Gemma
</span><span class='comment'># llm = Candle::LLM.from_pretrained(&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;, device: device)  # Llama
</span><span class='comment'># llm = Candle::LLM.from_pretrained(&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;, device: device)  # Mistral
</span>
<span class='comment'># Generate text
</span><span class='id identifier rubyid_response'>response</span> <span class='op'>=</span> <span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_generate'>generate</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>What is Ruby?</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>config:</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/GenerationConfig.html" title="Candle::GenerationConfig (class)">GenerationConfig</a></span></span><span class='period'>.</span><span class='id identifier rubyid_balanced'><span class='object_link'><a href="Candle/GenerationConfig.html#balanced-class_method" title="Candle::GenerationConfig.balanced (method)">balanced</a></span></span><span class='rparen'>)</span>

<span class='comment'># Stream generation
</span><span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_generate_stream'>generate_stream</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Tell me a story</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>config:</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/GenerationConfig.html" title="Candle::GenerationConfig (class)">GenerationConfig</a></span></span><span class='period'>.</span><span class='id identifier rubyid_balanced'><span class='object_link'><a href="Candle/GenerationConfig.html#balanced-class_method" title="Candle::GenerationConfig.balanced (method)">balanced</a></span></span><span class='rparen'>)</span> <span class='kw'>do</span> <span class='op'>|</span><span class='id identifier rubyid_token'>token</span><span class='op'>|</span>
  <span class='id identifier rubyid_print'>print</span> <span class='id identifier rubyid_token'>token</span>
<span class='kw'>end</span>

<span class='comment'># Chat interface
</span><span class='id identifier rubyid_messages'>messages</span> <span class='op'>=</span> <span class='lbracket'>[</span>
  <span class='lbrace'>{</span> <span class='label'>role:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>system</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>content:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>You are a helpful assistant.</span><span class='tstring_end'>&quot;</span></span> <span class='rbrace'>}</span><span class='comma'>,</span>
  <span class='lbrace'>{</span> <span class='label'>role:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>user</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>content:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Explain Ruby in one sentence.</span><span class='tstring_end'>&quot;</span></span> <span class='rbrace'>}</span>
<span class='rbracket'>]</span>
<span class='id identifier rubyid_response'>response</span> <span class='op'>=</span> <span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_chat'>chat</span><span class='lparen'>(</span><span class='id identifier rubyid_messages'>messages</span><span class='rparen'>)</span>
</code></pre>

<h3 id="gpu-acceleration">GPU Acceleration</h3>

<p>We see an 18x speed up running LLMs under CUDA vs CPU and a &gt;3x speed up running under Metal vs CPU. Details <a href="DEVICE_SUPPORT.md#performance-considerations">here</a>.</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># CPU works for all models
</span><span class='id identifier rubyid_device'>device</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_cpu'>cpu</span>
<span class='id identifier rubyid_llm'>llm</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/LLM.html#from_pretrained-class_method" title="Candle::LLM.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>TinyLlama/TinyLlama-1.1B-Chat-v1.0</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>device:</span> <span class='id identifier rubyid_device'>device</span><span class='rparen'>)</span>

<span class='comment'># Metal
</span><span class='id identifier rubyid_device'>device</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_metal'>metal</span> 

<span class='comment'># CUDA support (for NVIDIA GPUs COMING SOON)
</span><span class='id identifier rubyid_device'>device</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_cuda'>cuda</span>   <span class='comment'># Linux/Windows with NVIDIA GPU
</span></code></pre>

<h3 id="debugging-token-generation">Debugging Token Generation</h3>

<p>For debugging purposes, you can enable raw token output to see both token IDs and their raw representations:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Enable debug mode to see raw tokens during generation
</span><span class='id identifier rubyid_config'>config</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/GenerationConfig.html" title="Candle::GenerationConfig (class)">GenerationConfig</a></span></span><span class='period'>.</span><span class='id identifier rubyid_balanced'><span class='object_link'><a href="Candle/GenerationConfig.html#balanced-class_method" title="Candle::GenerationConfig.balanced (method)">balanced</a></span></span><span class='lparen'>(</span><span class='label'>debug_tokens:</span> <span class='kw'>true</span><span class='rparen'>)</span>

<span class='comment'># Non-streaming generation with debug tokens
</span><span class='id identifier rubyid_result'>result</span> <span class='op'>=</span> <span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_generate'>generate</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hello, world!</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>config:</span> <span class='id identifier rubyid_config'>config</span><span class='rparen'>)</span>
<span class='id identifier rubyid_puts'>puts</span> <span class='id identifier rubyid_result'>result</span>
<span class='comment'># Output: [15043:Hello][11:,][1917:world][0:!]
</span>
<span class='comment'># Streaming generation with debug tokens
</span><span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_generate_stream'>generate_stream</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hello, world!</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>config:</span> <span class='id identifier rubyid_config'>config</span><span class='rparen'>)</span> <span class='kw'>do</span> <span class='op'>|</span><span class='id identifier rubyid_text'>text</span><span class='op'>|</span>
  <span class='id identifier rubyid_print'>print</span> <span class='id identifier rubyid_text'>text</span>  <span class='comment'># Will show each token as it&#39;s generated: [15043:Hello][11:,][1917:world][0:!]
</span><span class='kw'>end</span>

<span class='comment'># Works with all models (Llama, Mistral, Gemma, and quantized GGUF models)
</span></code></pre>

<p>This is particularly useful for:</p>

<ul>
<li>Debugging tokenization issues</li>
<li>Understanding how the model processes text</li>
<li>Troubleshooting generation problems</li>
<li>Analyzing model behavior</li>
</ul>

<h2 id="model-format-requirements">‚ö†Ô∏è Model Format Requirements</h2>

<h3 id="embeddingmodels-and-rerankers-safetensors-only">EmbeddingModels and Rerankers: Safetensors Only</h3>

<p>Red-Candle <strong>only supports embedding models and rerankers that provide their weights in the <a href="https://github.com/huggingface/safetensors">safetensors</a> format</strong> (i.e., the model repo must contain a <code>model.safetensors</code> file). If the model repo does not provide the required file, loading will fail with a clear error. Most official BERT and DistilBERT models do <strong>not</strong> provide safetensors; many Sentence Transformers and JinaBERT models do.</p>

<p><strong>If you encounter an error like:</strong></p>

<pre class="code ruby"><code class="ruby">RuntimeError: model.safetensors not found after download. Only safetensors models are supported. Please ensure your model repo contains model.safetensors.
</code></pre>

<p>this means the selected model is not compatible. Please choose a model repo that provides the required file.</p>

<h3 id="llms-safetensors-and-gguf-support">LLMs: Safetensors and GGUF Support</h3>

<p>LLM models support two formats:</p>

<ol>
<li><strong>Safetensors format</strong> - Standard HuggingFace models (e.g., <code>TinyLlama/TinyLlama-1.1B-Chat-v1.0</code>)</li>
<li><strong>GGUF quantized format</strong> - Memory-efficient quantized models (e.g., <code>TheBloke/Llama-2-7B-Chat-GGUF</code>)</li>
</ol>

<p>See the <a href="#quantized-model-support-gguf">Quantized Model Support</a> section for details on using GGUF models.</p>

<h2 id="supported-embedding-models">Supported Embedding Models</h2>

<p>Red-Candle supports the following embedding model types from Hugging Face:</p>

<ol>
<li><code>Candle::EmbeddingModelType::JINA_BERT</code> - Jina BERT models (e.g., <code>jinaai/jina-embeddings-v2-base-en</code>) (<strong>safetensors required</strong>)</li>
<li><code>Candle::EmbeddingModelType::MINILM</code> - MINILM models (e.g., <code>sentence-transformers/all-MiniLM-L6-v2</code>) (<strong>safetensors required</strong>)</li>
<li><code>Candle::EmbeddingModelType::DISTILBERT</code> - DistilBERT models (e.g., <code>distilbert-base-uncased-finetuned-sst-2-english</code>) (<strong>safetensors required</strong>)</li>
<li><code>Candle::EmbeddingModelType::STANDARD_BERT</code> - Standard BERT models (e.g., <code>scientistcom/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</code>) (<strong>safetensors required</strong>)</li>
</ol>

<blockquote>
<p><strong>Note:</strong> Most official BERT and DistilBERT models do <em>not</em> provide safetensors. Please check the model repo before use.</p>
</blockquote>

<p>You can get a list of all supported model types and suggested models paths:</p>

<pre class="code ruby"><code class="ruby"><span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/EmbeddingModelType.html" title="Candle::EmbeddingModelType (module)">EmbeddingModelType</a></span></span><span class='period'>.</span><span class='id identifier rubyid_all'><span class='object_link'><a href="Candle/EmbeddingModelType.html#all-class_method" title="Candle::EmbeddingModelType.all (method)">all</a></span></span>  <span class='comment'># Returns all supported model types
</span><span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/EmbeddingModelType.html" title="Candle::EmbeddingModelType (module)">EmbeddingModelType</a></span></span><span class='period'>.</span><span class='id identifier rubyid_suggested_model_paths'><span class='object_link'><a href="Candle/EmbeddingModelType.html#suggested_model_paths-class_method" title="Candle::EmbeddingModelType.suggested_model_paths (method)">suggested_model_paths</a></span></span>  <span class='comment'># Returns hash of suggested models for each type
</span></code></pre>

<h2 id="a-note-on-memory-usage">A note on memory usage</h2>

<p>The default model (<code>jinaai/jina-embeddings-v2-base-en</code> with the <code>sentence-transformers/all-MiniLM-L6-v2</code> tokenizer, both from <a href="https://huggingface.co">HuggingFace</a>) takes a little more than 3GB of memory running on a Mac. The memory stays with the instantiated <code>Candle::EmbeddingModel</code> class, if you instantiate more than one, you&#39;ll use more memory. Likewise, if you let it go out of scope and call the garbage collector, you&#39;ll free the memory. For example:</p>

<pre class="code ruby"><code class="ruby">&gt; require &#39;candle&#39;
# Ruby memory = 25.9 MB
&gt; model = Candle::EmbeddingModel.new
# Ruby memory = 3.50 GB
&gt; model2 = Candle::EmbeddingModel.new
# Ruby memory = 7.04 GB
&gt; model2 = nil
&gt; GC.start
# Ruby memory = 3.56 GB
&gt; model = nil
&gt; GC.start
# Ruby memory = 55.2 MB
</code></pre>

<h2 id="a-note-on-returned-embeddings">A note on returned embeddings</h2>

<p>The code should match the same embeddings when generated from the python <code>transformers</code> library. For instance, locally I was able to generate the same embedding for the text &quot;Hi there!&quot; using the python code:</p>

<pre class="code python"><code class="python">from transformers import AutoModel
model = AutoModel.from_pretrained(&#39;jinaai/jina-embeddings-v2-base-en&#39;, trust_remote_code=True)
sentence = [&#39;Hi there!&#39;]
embedding = model.encode(sentence)
print(embedding)
</code></pre>

<p>And the following ruby:</p>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&#39;</span></span>
<span class='id identifier rubyid_model'>model</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/EmbeddingModel.html" title="Candle::EmbeddingModel (class)">EmbeddingModel</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/EmbeddingModel.html#new-class_method" title="Candle::EmbeddingModel.new (method)">new</a></span></span>
<span class='id identifier rubyid_embedding'>embedding</span> <span class='op'>=</span> <span class='id identifier rubyid_model'>model</span><span class='period'>.</span><span class='id identifier rubyid_embedding'>embedding</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hi there!</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
</code></pre>

<h2 id="document-reranking">Document Reranking</h2>

<p>Red-Candle includes support for cross-encoder reranking models, which can be used to reorder documents by relevance to a query. This is particularly useful for improving search results or implementing retrieval-augmented generation (RAG) systems.</p>

<h3 id="basic-usage">Basic Usage</h3>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&#39;</span></span>

<span class='comment'># Initialize the reranker with a cross-encoder model
</span><span class='id identifier rubyid_reranker'>reranker</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/Reranker.html" title="Candle::Reranker (class)">Reranker</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/Reranker.html#new-class_method" title="Candle::Reranker.new (method)">new</a></span></span><span class='lparen'>(</span><span class='label'>model_path:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>cross-encoder/ms-marco-MiniLM-L-12-v2</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Define your query and candidate documents
</span><span class='id identifier rubyid_query'>query</span> <span class='op'>=</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>How many people live in London?</span><span class='tstring_end'>&quot;</span></span>
<span class='id identifier rubyid_documents'>documents</span> <span class='op'>=</span> <span class='lbracket'>[</span>
  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>London is known for its financial district</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span>
  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Around 9 Million people live in London</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> 
  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>The weather in London is often rainy</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span>
  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>London is the capital of England</span><span class='tstring_end'>&quot;</span></span>
<span class='rbracket'>]</span>

<span class='comment'># Rerank documents by relevance to the query (raw logits)
</span><span class='id identifier rubyid_ranked_results'>ranked_results</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_rerank'>rerank</span><span class='lparen'>(</span><span class='id identifier rubyid_query'>query</span><span class='comma'>,</span> <span class='id identifier rubyid_documents'>documents</span><span class='comma'>,</span> <span class='label'>pooling_method:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>pooler</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>apply_sigmoid:</span> <span class='kw'>false</span><span class='rparen'>)</span>

<span class='comment'># Or apply sigmoid activation to get scores between 0 and 1
</span><span class='id identifier rubyid_sigmoid_results'>sigmoid_results</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_rerank'>rerank</span><span class='lparen'>(</span><span class='id identifier rubyid_query'>query</span><span class='comma'>,</span> <span class='id identifier rubyid_documents'>documents</span><span class='comma'>,</span> <span class='label'>pooling_method:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>pooler</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>apply_sigmoid:</span> <span class='kw'>true</span><span class='rparen'>)</span>

<span class='comment'># The pooler method is the default and is recommended for cross-encoders, as is apply_sigmoid, so the above is the same as:
</span><span class='id identifier rubyid_ranked_results'>ranked_results</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_rerank'>rerank</span><span class='lparen'>(</span><span class='id identifier rubyid_query'>query</span><span class='comma'>,</span> <span class='id identifier rubyid_documents'>documents</span><span class='rparen'>)</span>

<span class='comment'># Results are returned as an array of hashes, sorted by relevance
</span><span class='id identifier rubyid_e'>e</span><span class='period'>.</span><span class='id identifier rubyid_g'>g</span><span class='period'>.</span>
<span class='id identifier rubyid_ranked_results'>ranked_results</span><span class='period'>.</span><span class='id identifier rubyid_each'>each</span> <span class='kw'>do</span> <span class='op'>|</span><span class='id identifier rubyid_result'>result</span><span class='op'>|</span>
  <span class='id identifier rubyid_puts'>puts</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Score: </span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_result'>result</span><span class='lbracket'>[</span><span class='symbol'>:score</span><span class='rbracket'>]</span><span class='period'>.</span><span class='id identifier rubyid_round'>round</span><span class='lparen'>(</span><span class='int'>4</span><span class='rparen'>)</span><span class='embexpr_end'>}</span><span class='tstring_content'> - Doc #</span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_result'>result</span><span class='lbracket'>[</span><span class='symbol'>:doc_id</span><span class='rbracket'>]</span><span class='embexpr_end'>}</span><span class='tstring_content'>: </span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_result'>result</span><span class='lbracket'>[</span><span class='symbol'>:text</span><span class='rbracket'>]</span><span class='embexpr_end'>}</span><span class='tstring_end'>&quot;</span></span>
<span class='kw'>end</span>
<span class='comment'># Output:
</span><span class='comment'># Score: 1.0 - Doc #1: Around 9 Million people live in London
</span><span class='comment'># Score: 0.0438 - Doc #3: London is the capital of England
</span><span class='comment'># Score: 0.0085 - Doc #0: London is known for its financial district
</span><span class='comment'># Score: 0.0005 - Doc #2: The weather in London is often rainy
</span></code></pre>

<h3 id="arguments-activation-functions">Arguments &amp; Activation Functions</h3>

<p>By default, <code>apply_sigmoid</code> is <code>true</code> (scores between 0 and 1). Set it to <code>false</code> to get raw logits. You can also select the pooling method:</p>

<ul>
<li><code>pooling_method: &quot;pooler&quot;</code> (default)</li>
<li><code>pooling_method: &quot;cls&quot;</code></li>
<li><code>pooling_method: &quot;mean&quot;</code></li>
</ul>

<p>Example without sigmoid activation:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Get raw logits
</span><span class='id identifier rubyid_ranked_results'>ranked_results</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_rerank'>rerank</span><span class='lparen'>(</span><span class='id identifier rubyid_query'>query</span><span class='comma'>,</span> <span class='id identifier rubyid_documents'>documents</span><span class='comma'>,</span> <span class='label'>apply_sigmoid:</span> <span class='kw'>false</span><span class='rparen'>)</span>

<span class='id identifier rubyid_ranked_results'>ranked_results</span><span class='period'>.</span><span class='id identifier rubyid_each'>each</span> <span class='kw'>do</span> <span class='op'>|</span><span class='id identifier rubyid_result'>result</span><span class='op'>|</span>
  <span class='id identifier rubyid_puts'>puts</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Score: </span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_result'>result</span><span class='lbracket'>[</span><span class='symbol'>:score</span><span class='rbracket'>]</span><span class='period'>.</span><span class='id identifier rubyid_round'>round</span><span class='lparen'>(</span><span class='int'>4</span><span class='rparen'>)</span><span class='embexpr_end'>}</span><span class='tstring_content'> - Doc #</span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_result'>result</span><span class='lbracket'>[</span><span class='symbol'>:doc_id</span><span class='rbracket'>]</span><span class='embexpr_end'>}</span><span class='tstring_content'>: </span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_result'>result</span><span class='lbracket'>[</span><span class='symbol'>:text</span><span class='rbracket'>]</span><span class='embexpr_end'>}</span><span class='tstring_end'>&quot;</span></span>
<span class='kw'>end</span>
<span class='comment'># Output:
</span><span class='comment'># Score: 10.3918 - Doc #1: Around 9 Million people live in London
</span><span class='comment'># Score: -3.0829 - Doc #3: London is the capital of England
</span><span class='comment'># Score: -4.7619 - Doc #0: London is known for its financial district
</span><span class='comment'># Score: -7.5251 - Doc #2: The weather in London is often rainy
</span></code></pre>

<h3 id="output-format">Output Format</h3>

<p>The reranker returns an array of hashes, each with the following keys:</p>

<ul>
<li><code>:text</code> ‚Äì The original document text</li>
<li><code>:score</code> ‚Äì The relevance score (raw logit or sigmoid-activated)</li>
<li><code>:doc_id</code> ‚Äì The original 0-based index of the document in the input array</li>
</ul>

<p>This format is compatible with the Informers gem, which returns results as hashes with <code>:doc_id</code> and <code>:score</code> keys. The <code>doc_id</code> allows you to map results back to your original data structure.</p>

<h3 id="pooling-methods">Pooling Methods</h3>

<p>The reranker supports different pooling strategies for aggregating BERT embeddings:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Use alternative pooling methods
</span><span class='comment'># &quot;pooler&quot; (default) - Uses the pooler layer with tanh activation (most accurate for cross-encoders)
</span><span class='comment'># &quot;cls&quot; - Uses raw [CLS] token embeddings without the pooler layer
</span><span class='comment'># &quot;mean&quot; - Mean pooling across all tokens (not recommended for cross-encoders)
</span>
<span class='comment'># With raw logits
</span><span class='id identifier rubyid_results'>results</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_rerank_with_pooling'>rerank_with_pooling</span><span class='lparen'>(</span><span class='id identifier rubyid_query'>query</span><span class='comma'>,</span> <span class='id identifier rubyid_documents'>documents</span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>cls</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># With sigmoid activation
</span><span class='id identifier rubyid_results'>results</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_rerank_sigmoid_with_pooling'>rerank_sigmoid_with_pooling</span><span class='lparen'>(</span><span class='id identifier rubyid_query'>query</span><span class='comma'>,</span> <span class='id identifier rubyid_documents'>documents</span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>cls</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
</code></pre>

<p>Note: The default &quot;pooler&quot; method is recommended as it matches how cross-encoder models are trained. Other pooling methods may produce different ranking results.</p>

<h3 id="cuda-support">CUDA Support</h3>

<p>For faster inference on NVIDIA GPUs:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Initialize with CUDA if available (falls back to CPU if not)
</span><span class='id identifier rubyid_reranker'>reranker</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/Reranker.html" title="Candle::Reranker (class)">Reranker</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/Reranker.html#new-class_method" title="Candle::Reranker.new (method)">new</a></span></span><span class='lparen'>(</span><span class='label'>model_path:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>cross-encoder/ms-marco-MiniLM-L-12-v2</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>cuda:</span> <span class='kw'>true</span><span class='rparen'>)</span>
</code></pre>

<h3 id="how-it-works">How It Works</h3>

<p>Cross-encoder reranking models differ from bi-encoder embedding models:</p>

<ul>
<li><strong>Bi-encoders</strong> (like the embedding models above) encode queries and documents separately into dense vectors</li>
<li><strong>Cross-encoders</strong> process the query and document together, allowing for more nuanced relevance scoring</li>
</ul>

<p>The reranker uses a BERT-based architecture that:</p>

<ol>
<li>Concatenates the query and document with special tokens: <code>[CLS] query [SEP] document [SEP]</code></li>
<li>Processes them jointly through BERT layers</li>
<li>Applies a pooler layer (dense + tanh) to the [CLS] token</li>
<li>Uses a classifier layer to produce a single relevance score</li>
</ol>

<p>This joint processing allows cross-encoders to capture subtle semantic relationships between queries and documents, making them more accurate for reranking tasks, though at the cost of higher computational requirements.</p>

<h2 id="tokenizer">Tokenizer</h2>

<p>Red-Candle provides direct access to tokenizers for text preprocessing and analysis. This is useful for understanding how models process text, debugging issues, and building custom NLP pipelines.</p>

<h3 id="basic-usage">Basic Usage</h3>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&#39;</span></span>

<span class='comment'># Load a tokenizer from HuggingFace
</span><span class='id identifier rubyid_tokenizer'>tokenizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/Tokenizer.html" title="Candle::Tokenizer (class)">Tokenizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'>from_pretrained</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>bert-base-uncased</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Encode text to token IDs
</span><span class='id identifier rubyid_token_ids'>token_ids</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_encode'>encode</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hello, world!</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='comment'># =&gt; [101, 7592, 1010, 2088, 999, 102]
</span>
<span class='comment'># Decode token IDs back to text
</span><span class='id identifier rubyid_text'>text</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_decode'>decode</span><span class='lparen'>(</span><span class='id identifier rubyid_token_ids'>token_ids</span><span class='rparen'>)</span>
<span class='comment'># =&gt; &quot;hello, world!&quot;
</span>
<span class='comment'># Get token strings (subwords) - useful for visualization
</span><span class='id identifier rubyid_tokens'>tokens</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_encode_to_tokens'>encode_to_tokens</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hello, world!</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='comment'># =&gt; [&quot;[CLS]&quot;, &quot;hello&quot;, &quot;,&quot;, &quot;world&quot;, &quot;!&quot;, &quot;[SEP]&quot;]
</span>
<span class='comment'># Get both IDs and tokens together
</span><span class='id identifier rubyid_result'>result</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_encode_with_tokens'>encode_with_tokens</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>preprocessing</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='comment'># =&gt; {&quot;ids&quot; =&gt; [101, 3653, 22618, 2527, 102], 
</span><span class='comment'>#     &quot;tokens&quot; =&gt; [&quot;[CLS]&quot;, &quot;prep&quot;, &quot;##ro&quot;, &quot;##ces&quot;, &quot;##sing&quot;, &quot;[SEP]&quot;]}
</span></code></pre>

<h3 id="batch-processing">Batch Processing</h3>

<pre class="code ruby"><code class="ruby"><span class='comment'># Encode multiple texts at once
</span><span class='id identifier rubyid_texts'>texts</span> <span class='op'>=</span> <span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Hello world</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>How are you?</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Tokenizers are cool</span><span class='tstring_end'>&quot;</span></span><span class='rbracket'>]</span>
<span class='id identifier rubyid_batch_ids'>batch_ids</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_encode_batch'>encode_batch</span><span class='lparen'>(</span><span class='id identifier rubyid_texts'>texts</span><span class='rparen'>)</span>

<span class='comment'># Get token strings for multiple texts
</span><span class='id identifier rubyid_batch_tokens'>batch_tokens</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_encode_batch_to_tokens'>encode_batch_to_tokens</span><span class='lparen'>(</span><span class='id identifier rubyid_texts'>texts</span><span class='rparen'>)</span>
</code></pre>

<h3 id="vocabulary-access">Vocabulary Access</h3>

<pre class="code ruby"><code class="ruby"><span class='comment'># Get vocabulary size
</span><span class='id identifier rubyid_vocab_size'>vocab_size</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_vocab_size'>vocab_size</span>
<span class='comment'># =&gt; 30522
</span>
<span class='comment'># Get full vocabulary as a hash
</span><span class='id identifier rubyid_vocab'>vocab</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_get_vocab'>get_vocab</span>
<span class='comment'># vocab[&quot;hello&quot;] =&gt; 7592
</span>
<span class='comment'># Convert a specific token ID to its string
</span><span class='id identifier rubyid_token_str'>token_str</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_id_to_token'>id_to_token</span><span class='lparen'>(</span><span class='int'>7592</span><span class='rparen'>)</span>
<span class='comment'># =&gt; &quot;hello&quot;
</span>
<span class='comment'># Get special tokens
</span><span class='id identifier rubyid_special'>special</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_get_special_tokens'>get_special_tokens</span>
<span class='comment'># =&gt; {&quot;cls_token&quot; =&gt; 101, &quot;sep_token&quot; =&gt; 102, &quot;pad_token&quot; =&gt; 0, ...}
</span></code></pre>

<h3 id="configuration">Configuration</h3>

<pre class="code ruby"><code class="ruby"><span class='comment'># Create a tokenizer with padding enabled
</span><span class='id identifier rubyid_padded_tokenizer'>padded_tokenizer</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_with_padding'>with_padding</span><span class='lparen'>(</span><span class='label'>length:</span> <span class='int'>128</span><span class='rparen'>)</span>

<span class='comment'># Create a tokenizer with truncation
</span><span class='id identifier rubyid_truncated_tokenizer'>truncated_tokenizer</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_with_truncation'>with_truncation</span><span class='lparen'>(</span><span class='int'>512</span><span class='rparen'>)</span>

<span class='comment'># Configure padding with more options
</span><span class='id identifier rubyid_padded_tokenizer'>padded_tokenizer</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_with_padding'>with_padding</span><span class='lparen'>(</span>
  <span class='label'>length:</span> <span class='int'>128</span><span class='comma'>,</span>          <span class='comment'># Fixed length padding
</span>  <span class='label'>direction:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>right</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span>   <span class='comment'># Pad on the right (default)
</span>  <span class='label'>pad_token:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>[PAD]</span><span class='tstring_end'>&quot;</span></span>    <span class='comment'># Padding token
</span><span class='rparen'>)</span>
</code></pre>

<h3 id="model-integration">Model Integration</h3>

<p>All models expose their tokenizers:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># From LLM
</span><span class='id identifier rubyid_llm'>llm</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/LLM.html#from_pretrained-class_method" title="Candle::LLM.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>TinyLlama/TinyLlama-1.1B-Chat-v1.0</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='id identifier rubyid_llm_tokenizer'>llm_tokenizer</span> <span class='op'>=</span> <span class='id identifier rubyid_llm'>llm</span><span class='period'>.</span><span class='id identifier rubyid_tokenizer'>tokenizer</span>

<span class='comment'># From EmbeddingModel
</span><span class='id identifier rubyid_embedding_model'>embedding_model</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/EmbeddingModel.html" title="Candle::EmbeddingModel (class)">EmbeddingModel</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/EmbeddingModel.html#new-class_method" title="Candle::EmbeddingModel.new (method)">new</a></span></span>
<span class='id identifier rubyid_emb_tokenizer'>emb_tokenizer</span> <span class='op'>=</span> <span class='id identifier rubyid_embedding_model'>embedding_model</span><span class='period'>.</span><span class='id identifier rubyid_tokenizer'>tokenizer</span>

<span class='comment'># From Reranker
</span><span class='id identifier rubyid_reranker'>reranker</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/Reranker.html" title="Candle::Reranker (class)">Reranker</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/Reranker.html#new-class_method" title="Candle::Reranker.new (method)">new</a></span></span><span class='lparen'>(</span><span class='label'>model_path:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>cross-encoder/ms-marco-MiniLM-L-12-v2</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='id identifier rubyid_rank_tokenizer'>rank_tokenizer</span> <span class='op'>=</span> <span class='id identifier rubyid_reranker'>reranker</span><span class='period'>.</span><span class='id identifier rubyid_tokenizer'>tokenizer</span>
</code></pre>

<h3 id="understanding-subword-tokenization">Understanding Subword Tokenization</h3>

<p>Modern tokenizers split unknown or rare words into subword pieces:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># See how words are split into subwords
</span><span class='id identifier rubyid_result'>result</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_encode_with_tokens'>encode_with_tokens</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>unbelievable</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='comment'># =&gt; {&quot;ids&quot; =&gt; [101, 4895, 6499, 102], 
</span><span class='comment'>#     &quot;tokens&quot; =&gt; [&quot;[CLS]&quot;, &quot;un&quot;, &quot;##believable&quot;, &quot;[SEP]&quot;]}
</span>
<span class='comment'># The ## prefix indicates a continuation of the previous token
</span><span class='id identifier rubyid_complex'>complex</span> <span class='op'>=</span> <span class='id identifier rubyid_tokenizer'>tokenizer</span><span class='period'>.</span><span class='id identifier rubyid_encode_to_tokens'>encode_to_tokens</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>preprocessing tokenization</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='comment'># =&gt; [&quot;[CLS]&quot;, &quot;prep&quot;, &quot;##ro&quot;, &quot;##ces&quot;, &quot;##sing&quot;, &quot;token&quot;, &quot;##ization&quot;, &quot;[SEP]&quot;]
</span></code></pre>

<h3 id="use-cases">Use Cases</h3>

<ul>
<li><strong>Token Analysis</strong>: Understand how your text is being processed by models</li>
<li><strong>Debugging</strong>: See why certain inputs might cause unexpected model behavior<br></li>
<li><strong>Custom Preprocessing</strong>: Build your own text processing pipelines</li>
<li><strong>Educational</strong>: Teach how modern NLP models handle text</li>
<li><strong>NER Preparation</strong>: Get aligned tokens for named entity recognition tasks</li>
</ul>

<h2 id="named-entity-recognition-ner">Named Entity Recognition (NER)</h2>

<p>Red-Candle includes comprehensive Named Entity Recognition capabilities for extracting entities like people, organizations, locations, and custom entity types from text.</p>

<h3 id="model-based-ner">Model-based NER</h3>

<p>Load pre-trained NER models from HuggingFace:</p>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_require'>require</span> <span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>candle</span><span class='tstring_end'>&#39;</span></span>

<span class='comment'># Load a pre-trained NER model
</span><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Babelscape/wikineural-multilingual-ner</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Or load a model with a specific tokenizer (for models without tokenizer.json)
</span><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>dslim/bert-base-NER</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>tokenizer:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>bert-base-cased</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Extract entities from text
</span><span class='id identifier rubyid_text'>text</span> <span class='op'>=</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Apple Inc. was founded by Steve Jobs and Steve Wozniak in Cupertino, California.</span><span class='tstring_end'>&quot;</span></span>
<span class='id identifier rubyid_entities'>entities</span> <span class='op'>=</span> <span class='id identifier rubyid_ner'>ner</span><span class='period'>.</span><span class='id identifier rubyid_extract_entities'>extract_entities</span><span class='lparen'>(</span><span class='id identifier rubyid_text'>text</span><span class='rparen'>)</span>

<span class='id identifier rubyid_entities'>entities</span><span class='period'>.</span><span class='id identifier rubyid_each'>each</span> <span class='kw'>do</span> <span class='op'>|</span><span class='id identifier rubyid_entity'>entity</span><span class='op'>|</span>
  <span class='id identifier rubyid_puts'>puts</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_entity'>entity</span><span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>text</span><span class='tstring_end'>&#39;</span></span><span class='rbracket'>]</span><span class='embexpr_end'>}</span><span class='tstring_content'> (</span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_entity'>entity</span><span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>label</span><span class='tstring_end'>&#39;</span></span><span class='rbracket'>]</span><span class='embexpr_end'>}</span><span class='tstring_content'>) - confidence: </span><span class='embexpr_beg'>#{</span><span class='id identifier rubyid_entity'>entity</span><span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&#39;</span><span class='tstring_content'>confidence</span><span class='tstring_end'>&#39;</span></span><span class='rbracket'>]</span><span class='period'>.</span><span class='id identifier rubyid_round'>round</span><span class='lparen'>(</span><span class='int'>2</span><span class='rparen'>)</span><span class='embexpr_end'>}</span><span class='tstring_end'>&quot;</span></span>
<span class='kw'>end</span>
<span class='comment'># Output:
</span><span class='comment'># Apple Inc. (ORG) - confidence: 0.99
</span><span class='comment'># Steve Jobs (PER) - confidence: 0.99
</span><span class='comment'># Steve Wozniak (PER) - confidence: 0.98
</span><span class='comment'># Cupertino (LOC) - confidence: 0.97
</span><span class='comment'># California (LOC) - confidence: 0.98
</span>
<span class='comment'># Adjust confidence threshold (default: 0.9)
</span><span class='id identifier rubyid_entities'>entities</span> <span class='op'>=</span> <span class='id identifier rubyid_ner'>ner</span><span class='period'>.</span><span class='id identifier rubyid_extract_entities'>extract_entities</span><span class='lparen'>(</span><span class='id identifier rubyid_text'>text</span><span class='comma'>,</span> <span class='label'>confidence_threshold:</span> <span class='float'>0.95</span><span class='rparen'>)</span>

<span class='comment'># Get token-level predictions for detailed analysis
</span><span class='id identifier rubyid_tokens'>tokens</span> <span class='op'>=</span> <span class='id identifier rubyid_ner'>ner</span><span class='period'>.</span><span class='id identifier rubyid_predict_tokens'>predict_tokens</span><span class='lparen'>(</span><span class='id identifier rubyid_text'>text</span><span class='rparen'>)</span>
</code></pre>

<h3 id="pattern-based-recognition">Pattern-based Recognition</h3>

<p>For domain-specific entities, use regex patterns:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Create pattern-based recognizers
</span><span class='id identifier rubyid_email_recognizer'>email_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html" title="Candle::PatternEntityRecognizer (class)">PatternEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html#initialize-instance_method" title="Candle::PatternEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>EMAIL</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='lbracket'>[</span>
  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b</span><span class='regexp_end'>/</span></span>
<span class='rbracket'>]</span><span class='rparen'>)</span>

<span class='id identifier rubyid_phone_recognizer'>phone_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html" title="Candle::PatternEntityRecognizer (class)">PatternEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html#initialize-instance_method" title="Candle::PatternEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>PHONE</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='lbracket'>[</span>
  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b\d{3}[-.]?\d{3}[-.]?\d{4}\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>         <span class='comment'># 555-123-4567
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b\(\d{3}\)\s*\d{3}[-.]?\d{4}\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>      <span class='comment'># (555) 123-4567
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b\+1\s*\d{3}[-.]?\d{3}[-.]?\d{4}\b</span><span class='regexp_end'>/</span></span>   <span class='comment'># +1 555-123-4567
</span><span class='rbracket'>]</span><span class='rparen'>)</span>

<span class='comment'># Extract entities
</span><span class='id identifier rubyid_text'>text</span> <span class='op'>=</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Contact us at info@example.com or call 555-123-4567</span><span class='tstring_end'>&quot;</span></span>
<span class='id identifier rubyid_email_entities'>email_entities</span> <span class='op'>=</span> <span class='id identifier rubyid_email_recognizer'>email_recognizer</span><span class='period'>.</span><span class='id identifier rubyid_recognize'>recognize</span><span class='lparen'>(</span><span class='id identifier rubyid_text'>text</span><span class='rparen'>)</span>
<span class='id identifier rubyid_phone_entities'>phone_entities</span> <span class='op'>=</span> <span class='id identifier rubyid_phone_recognizer'>phone_recognizer</span><span class='period'>.</span><span class='id identifier rubyid_recognize'>recognize</span><span class='lparen'>(</span><span class='id identifier rubyid_text'>text</span><span class='rparen'>)</span>
</code></pre>

<h3 id="gazetteer-based-recognition">Gazetteer-based Recognition</h3>

<p>Use dictionaries for known entities:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Create gazetteer recognizers
</span><span class='id identifier rubyid_companies'>companies</span> <span class='op'>=</span> <span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Apple</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Google</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Microsoft</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Amazon</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Tesla</span><span class='tstring_end'>&quot;</span></span><span class='rbracket'>]</span>
<span class='id identifier rubyid_company_recognizer'>company_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/GazetteerEntityRecognizer.html" title="Candle::GazetteerEntityRecognizer (class)">GazetteerEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/GazetteerEntityRecognizer.html#initialize-instance_method" title="Candle::GazetteerEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>COMPANY</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='id identifier rubyid_companies'>companies</span><span class='rparen'>)</span>

<span class='comment'># Load from file
</span><span class='id identifier rubyid_drug_recognizer'>drug_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/GazetteerEntityRecognizer.html" title="Candle::GazetteerEntityRecognizer (class)">GazetteerEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/GazetteerEntityRecognizer.html#initialize-instance_method" title="Candle::GazetteerEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>DRUG</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='id identifier rubyid_drug_recognizer'>drug_recognizer</span><span class='period'>.</span><span class='id identifier rubyid_load_from_file'>load_from_file</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>drug_names.txt</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Case-sensitive matching
</span><span class='id identifier rubyid_product_recognizer'>product_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/GazetteerEntityRecognizer.html" title="Candle::GazetteerEntityRecognizer (class)">GazetteerEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/GazetteerEntityRecognizer.html#initialize-instance_method" title="Candle::GazetteerEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>PRODUCT</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> 
  <span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>iPhone</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>iPad</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>MacBook</span><span class='tstring_end'>&quot;</span></span><span class='rbracket'>]</span><span class='comma'>,</span> 
  <span class='label'>case_sensitive:</span> <span class='kw'>true</span>
<span class='rparen'>)</span>
</code></pre>

<h3 id="hybrid-ner">Hybrid NER</h3>

<p>Combine ML models with rule-based approaches for best results:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Create hybrid NER system
</span><span class='id identifier rubyid_hybrid'>hybrid</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/HybridNER.html" title="Candle::HybridNER (class)">HybridNER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/HybridNER.html#initialize-instance_method" title="Candle::HybridNER#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Babelscape/wikineural-multilingual-ner</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Add pattern recognizers
</span><span class='id identifier rubyid_hybrid'>hybrid</span><span class='period'>.</span><span class='id identifier rubyid_add_pattern_recognizer'>add_pattern_recognizer</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>EMAIL</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='lbracket'>[</span><span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b[\w._%+-]+@[\w.-]+\.[A-Z|a-z]{2,}\b</span><span class='regexp_end'>/</span></span><span class='rbracket'>]</span><span class='rparen'>)</span>
<span class='id identifier rubyid_hybrid'>hybrid</span><span class='period'>.</span><span class='id identifier rubyid_add_pattern_recognizer'>add_pattern_recognizer</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>PHONE</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='lbracket'>[</span><span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b\d{3}[-.]?\d{3}[-.]?\d{4}\b</span><span class='regexp_end'>/</span></span><span class='rbracket'>]</span><span class='rparen'>)</span>

<span class='comment'># Add gazetteer recognizers  
</span><span class='id identifier rubyid_hybrid'>hybrid</span><span class='period'>.</span><span class='id identifier rubyid_add_gazetteer_recognizer'>add_gazetteer_recognizer</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>COMPANY</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Apple</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Google</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Microsoft</span><span class='tstring_end'>&quot;</span></span><span class='rbracket'>]</span><span class='rparen'>)</span>
<span class='id identifier rubyid_hybrid'>hybrid</span><span class='period'>.</span><span class='id identifier rubyid_add_gazetteer_recognizer'>add_gazetteer_recognizer</span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>PRODUCT</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='lbracket'>[</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>iPhone</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Android</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Windows</span><span class='tstring_end'>&quot;</span></span><span class='rbracket'>]</span><span class='rparen'>)</span>

<span class='comment'># Extract all entities
</span><span class='id identifier rubyid_text'>text</span> <span class='op'>=</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>John Smith (john@apple.com) from Apple called about the new iPhone. Reach him at 555-0123.</span><span class='tstring_end'>&quot;</span></span>
<span class='id identifier rubyid_entities'>entities</span> <span class='op'>=</span> <span class='id identifier rubyid_hybrid'>hybrid</span><span class='period'>.</span><span class='id identifier rubyid_extract_entities'>extract_entities</span><span class='lparen'>(</span><span class='id identifier rubyid_text'>text</span><span class='rparen'>)</span>

<span class='comment'># Results include entities from all recognizers
</span><span class='comment'># Overlapping entities are automatically resolved (highest confidence wins)
</span></code></pre>

<h3 id="custom-entity-types">Custom Entity Types</h3>

<p>Perfect for specialized domains:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Biomedical entities
</span><span class='id identifier rubyid_gene_patterns'>gene_patterns</span> <span class='op'>=</span> <span class='lbracket'>[</span>
  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b[A-Z][A-Z0-9]{2,}\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>      <span class='comment'># TP53, BRCA1, EGFR
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\bCD\d+\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>                  <span class='comment'># CD4, CD8, CD34
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b[A-Z]+\d[A-Z]\d*\b</span><span class='regexp_end'>/</span></span>        <span class='comment'># RAD51C, PALB2
</span><span class='rbracket'>]</span>
<span class='id identifier rubyid_gene_recognizer'>gene_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html" title="Candle::PatternEntityRecognizer (class)">PatternEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html#initialize-instance_method" title="Candle::PatternEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>GENE</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='id identifier rubyid_gene_patterns'>gene_patterns</span><span class='rparen'>)</span>

<span class='comment'># Financial entities
</span><span class='id identifier rubyid_ticker_patterns'>ticker_patterns</span> <span class='op'>=</span> <span class='lbracket'>[</span>
  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\$[A-Z]{1,5}\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>             <span class='comment'># $AAPL, $GOOGL
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b[A-Z]{1,5}\.NYSE\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>       <span class='comment'># AAPL.NYSE
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b[A-Z]{1,5}\.NASDAQ\b</span><span class='regexp_end'>/</span></span>      <span class='comment'># GOOGL.NASDAQ
</span><span class='rbracket'>]</span>
<span class='id identifier rubyid_ticker_recognizer'>ticker_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html" title="Candle::PatternEntityRecognizer (class)">PatternEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html#initialize-instance_method" title="Candle::PatternEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>TICKER</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='id identifier rubyid_ticker_patterns'>ticker_patterns</span><span class='rparen'>)</span>

<span class='comment'># Legal entities
</span><span class='id identifier rubyid_case_patterns'>case_patterns</span> <span class='op'>=</span> <span class='lbracket'>[</span>
  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b\d+\s+F\.\d+\s+\d+\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>     <span class='comment'># 123 F.3d 456
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\b\d+\s+U\.S\.\s+\d+\b</span><span class='regexp_end'>/</span></span><span class='comma'>,</span>     <span class='comment'># 123 U.S. 456
</span>  <span class='tstring'><span class='regexp_beg'>/</span><span class='tstring_content'>\bNo\.\s+\d+-\d+\b</span><span class='regexp_end'>/</span></span>          <span class='comment'># No. 20-1234
</span><span class='rbracket'>]</span>
<span class='id identifier rubyid_case_recognizer'>case_recognizer</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html" title="Candle::PatternEntityRecognizer (class)">PatternEntityRecognizer</a></span></span><span class='period'>.</span><span class='id identifier rubyid_new'><span class='object_link'><a href="Candle/PatternEntityRecognizer.html#initialize-instance_method" title="Candle::PatternEntityRecognizer#initialize (method)">new</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>CASE</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='id identifier rubyid_case_patterns'>case_patterns</span><span class='rparen'>)</span>
</code></pre>

<h3 id="available-pre-trained-models">Available Pre-trained Models</h3>

<p>Popular NER models on HuggingFace:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># General multilingual NER (4 entity types: PER, ORG, LOC, MISC)
</span><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Babelscape/wikineural-multilingual-ner</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># English NER (requires separate tokenizer)
</span><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>dslim/bert-base-NER</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>tokenizer:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>bert-base-cased</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Multilingual NER  
</span><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Davlan/bert-base-multilingual-cased-ner-hrl</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># OntoNotes 5 (18 entity types including DATE, TIME, MONEY, etc.)
</span><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>flair/ner-english-ontonotes-large</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>

<span class='comment'># Biomedical NER
</span><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>dmis-lab/biobert-base-cased-v1.2</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
<span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>allenai/scibert_scivocab_uncased</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
</code></pre>

<h3 id="performance-tips">Performance Tips</h3>

<ol>
<li><p><strong>Device Selection</strong>: Use GPU for faster inference</p>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_ner'>ner</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/NER.html" title="Candle::NER (class)">NER</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/NER.html#from_pretrained-class_method" title="Candle::NER.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Babelscape/wikineural-multilingual-ner</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> <span class='label'>device:</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'>Device</span><span class='period'>.</span><span class='id identifier rubyid_metal'>metal</span><span class='rparen'>)</span>
</code></pre></li>
<li><p><strong>Batch Processing</strong>: Process multiple texts together when possible</p></li>
<li><p><strong>Confidence Threshold</strong>: Balance precision/recall with appropriate thresholds</p></li>
<li><p><strong>Entity Resolution</strong>: The hybrid NER automatically handles overlapping entities</p></li>
</ol>

<h3 id="output-format">Output Format</h3>

<p>All NER methods return entities in a consistent format:</p>

<pre class="code ruby"><code class="ruby"><span class='lbrace'>{</span>
  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>text</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>Apple Inc.</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span>          <span class='comment'># The entity text
</span>  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>label</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>ORG</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span>               <span class='comment'># Entity type
</span>  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>start</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='int'>0</span><span class='comma'>,</span>                   <span class='comment'># Character start position
</span>  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>end</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='int'>10</span><span class='comma'>,</span>                    <span class='comment'># Character end position  
</span>  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>confidence</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='float'>0.99</span><span class='comma'>,</span>           <span class='comment'># Confidence score (0-1)
</span>  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>token_start</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='int'>0</span><span class='comma'>,</span>             <span class='comment'># Token start index (model-based only)
</span>  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>token_end</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='int'>2</span><span class='comma'>,</span>               <span class='comment'># Token end index (model-based only)
</span>  <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>source</span><span class='tstring_end'>&quot;</span></span> <span class='op'>=&gt;</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>model</span><span class='tstring_end'>&quot;</span></span>             <span class='comment'># Source: &quot;model&quot;, &quot;pattern&quot;, or &quot;gazetteer&quot;
</span><span class='rbrace'>}</span>
</code></pre>

<h2 id="common-runtime-errors">Common Runtime Errors</h2>

<h3 id="weight-is-negative-too-large-or-not-a-valid-number">Weight is negative, too large or not a valid number</h3>

<p><strong>Error:</strong></p>

<pre class="code ruby"><code class="ruby">/Users/cpetersen/src/scientist/red-candle/lib/candle/llm.rb:25:in `_generate_stream&#39;: Generation failed: A weight is negative, too large or not a valid number (RuntimeError)
    from /Users/cpetersen/src/scientist/red-candle/lib/candle/llm.rb:25:in `generate_stream&#39;
    ...
</code></pre>

<p><strong>Cause:</strong> This error occurs when using overly aggressive quantization levels (particularly Q2_K) that result in numerical instability during inference. The 2-bit quantization can cause weights to become corrupted or produce NaN/Inf values.</p>

<p><strong>Solution:</strong> Use a higher quantization level. Recommended options:</p>

<ul>
<li>Q4_K_M (4-bit) - Best balance of quality and size</li>
<li>Q5_K_M (5-bit) - Higher quality with slightly larger size</li>
<li>Q3_K_M (3-bit) - Minimum recommended quantization</li>
</ul>

<pre class="code ruby"><code class="ruby"><span class='id identifier rubyid_llm'>llm</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/LLM.html#from_pretrained-class_method" title="Candle::LLM.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> 
                                  <span class='label'>device:</span> <span class='id identifier rubyid_device'>device</span><span class='comma'>,</span> 
                                  <span class='label'>gguf_file:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
</code></pre>

<h3 id="cannot-find-tensor-model-embed_tokens-weight">Cannot find tensor model.embed_tokens.weight</h3>

<p><strong>Error:</strong></p>

<pre class="code ruby"><code class="ruby">Failed to load quantized model: cannot find tensor model.embed_tokens.weight (RuntimeError)
</code></pre>

<p><strong>Cause:</strong> This error was common in earlier versions when loading GGUF files with incompatible tensor naming conventions. The unified GGUF loader in version 1.0.0+ should handle most GGUF files correctly.</p>

<p><strong>If you still encounter this error:</strong></p>

<ol>
<li>Ensure you&#39;re using the latest version of red-candle (1.0.0 or higher)</li>
<li>Make sure to specify the exact GGUF filename:
<code>ruby
llm = Candle::LLM.from_pretrained(&quot;TheBloke/Mistral-7B-Instruct-v0.2-GGUF&quot;, 
                                 device: device,
                                 gguf_file: &quot;mistral-7b-instruct-v0.2.Q4_K_M.gguf&quot;)
</code></li>
<li>If the error persists, the GGUF file may use an unsupported architecture or format</li>
</ol>

<h3 id="no-gguf-file-found-in-repository">No GGUF file found in repository</h3>

<p><strong>Error:</strong></p>

<pre class="code ruby"><code class="ruby">Failed to load quantized model: No GGUF file found in repository TheBloke/model-name-GGUF. Try specifying a quantization level like Q4_K_M, Q5_K_M, or Q8_0. (RuntimeError)
</code></pre>

<p><strong>Cause:</strong> The automatic GGUF file detection couldn&#39;t find a matching file, often due to naming variations.</p>

<p><strong>Solution:</strong> Specify the exact GGUF filename:</p>

<pre class="code ruby"><code class="ruby"><span class='comment'># Visit the HuggingFace repository to find the exact filename
</span><span class='id identifier rubyid_llm'>llm</span> <span class='op'>=</span> <span class='const'><span class='object_link'><a href="Candle.html" title="Candle (module)">Candle</a></span></span><span class='op'>::</span><span class='const'><span class='object_link'><a href="Candle/LLM.html" title="Candle::LLM (class)">LLM</a></span></span><span class='period'>.</span><span class='id identifier rubyid_from_pretrained'><span class='object_link'><a href="Candle/LLM.html#from_pretrained-class_method" title="Candle::LLM.from_pretrained (method)">from_pretrained</a></span></span><span class='lparen'>(</span><span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>TheBloke/Llama-2-7B-Chat-GGUF</span><span class='tstring_end'>&quot;</span></span><span class='comma'>,</span> 
                                  <span class='label'>device:</span> <span class='id identifier rubyid_device'>device</span><span class='comma'>,</span> 
                                  <span class='label'>gguf_file:</span> <span class='tstring'><span class='tstring_beg'>&quot;</span><span class='tstring_content'>llama-2-7b-chat.Q4_K_M.gguf</span><span class='tstring_end'>&quot;</span></span><span class='rparen'>)</span>
</code></pre>

<h3 id="failed-to-download-tokenizer">Failed to download tokenizer</h3>

<p><strong>Error:</strong></p>

<pre class="code ruby"><code class="ruby">Failed to load quantized model: Failed to download tokenizer: request error: HTTP status client error (404 Not Found)
</code></pre>

<p><strong>Cause:</strong> GGUF repositories often don&#39;t include separate tokenizer files since they&#39;re embedded in the GGUF format.</p>

<p><strong>Solution:</strong> The code now includes fallback tokenizer loading. If you still encounter this error, ensure you&#39;re using the latest version of red-candle.</p>

<h3 id="missing-metadata-in-gguf-file">Missing metadata in GGUF file</h3>

<p><strong>Error:</strong></p>

<pre class="code ruby"><code class="ruby">Failed to load GGUF model: cannot find gemma3.attention.head_count in metadata (RuntimeError)
</code></pre>

<p>or</p>

<pre class="code ruby"><code class="ruby">Failed to load GGUF model: cannot find llama.attention.head_count in metadata (RuntimeError)
</code></pre>

<p><strong>Cause:</strong> Some GGUF files may have been created with older conversion tools that don&#39;t include all required metadata fields.</p>

<p><strong>Solution:</strong> </p>

<ul>
<li>Try a different GGUF file from the same model</li>
<li>Look for GGUF files from TheBloke or other reputable sources</li>
<li>Check if a newer version of the GGUF file is available</li>
<li>Some Gemma GGUF files may not be compatible with the current loader</li>
</ul>

<p><strong>Known compatibility issues:</strong></p>

<ul>
<li><code>lmstudio-ai/gemma-2b-it-GGUF</code> - Missing required metadata fields</li>
<li>Gemma 3 GGUF files may require specific tokenizers that are not publicly available</li>
<li>For best compatibility, use Llama or Mistral GGUF files from TheBloke</li>
</ul>

<h2 id="development">Development</h2>

<p>FORK IT!</p>

<pre class="code ruby"><code class="ruby">git clone https://github.com/your_name/red-candle
cd red-candle
bundle
bundle exec rake compile
</code></pre>

<p>Pull requests are welcome.</p>

<h2 id="release">Release</h2>

<ol>
<li>Update version number in <code>lib/candle/version.rb</code> and commit.</li>
<li><code>bundle exec rake build</code></li>
<li><code>git tag VERSION_NUMBER</code></li>
<li><code>git push --follow-tags</code></li>
<li><code>gem push pkg/red-candle-1.0.0.gem</code></li>
</ol>

<h2 id="see-also">See Also</h2>

<ul>
<li><a href="https://github.com/huggingface/candle">Candle</a></li>
<li><a href="https://github.com/matsadler/magnus">Magnus</a></li>
<li><a href="https://github.com/dottxt-ai/outlines-core">Outlines-core</a></li>
</ul>
</div></div>

      <div id="footer">
  Generated on Sat Jul 19 22:35:11 2025 by
  <a href="https://yardoc.org" title="Yay! A Ruby Documentation Tool" target="_parent">yard</a>
  0.9.37 (ruby-3.4.5).
</div>

    </div>
  </body>
</html>